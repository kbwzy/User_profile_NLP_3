{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_sh.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oHVU3kHoqXnj","colab_type":"code","outputId":"37593963-8bae-4d5b-9b67-ae90ccd65437","executionInfo":{"status":"ok","timestamp":1571325504371,"user_tz":-480,"elapsed":88039,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":222}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 131183 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.13-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.13-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d0Z_Uge5qa6Q","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive # 此时colab中出现drive的文件夹，里面就是你的google drive的根目录文件"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNUAF2e4qf0J","colab_type":"code","outputId":"1d0f5598-adad-4d6a-84ec-b211f6150b57","executionInfo":{"status":"ok","timestamp":1571325519076,"user_tz":-480,"elapsed":3768,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["!ls -al"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 32\n","drwxr-xr-x 1 root root 4096 Oct 17 15:18 .\n","drwxr-xr-x 1 root root 4096 Oct 17 15:16 ..\n","-rw-r--r-- 1 root root 2661 Oct 17 15:18 adc.json\n","drwxr-xr-x 1 root root 4096 Oct 17 15:18 .config\n","drwxr-xr-x 2 root root 4096 Oct 17 15:18 drive\n","drwxr-xr-x 1 root root 4096 Aug 27 16:17 sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HCIQ9mQzqjjX","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"drive/Colab Notebooks/Team management/ccf2016_sougou\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsjQQ8a3TKdI","colab_type":"code","outputId":"6125ab87-8447-454c-c456-5a64a3195bdd","executionInfo":{"status":"ok","timestamp":1571325530370,"user_tz":-480,"elapsed":3071,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["!ls -al"],"execution_count":0,"outputs":[{"output_type":"stream","text":["total 89\n","drwxr-xr-x 2 root root  4096 Oct 15 08:25  .\n","drwxr-xr-x 2 root root  4096 Oct 15 01:58  ..\n","-rw-r--r-- 1 root root  6349 Oct 17 14:52 '1.NLP实战项目 -- 基于自然语言处理的搜索引擎公司用户画像.ipynb'\n","-rw-r--r-- 1 root root 37842 Oct 17 14:52  2.项目思路.ipynb\n","-rw-r--r-- 1 root root  2993 Oct 17 14:52  d2v_model.py\n","drwxr-xr-x 2 root root  4096 Oct 17 14:52  data\n","-rw-r--r-- 1 root root  2537 Oct 17 14:52  dbow_nn_stack.py\n","-rw-r--r-- 1 root root  2363 Oct 17 14:52  dm_nn_stack.py\n","-rw-r--r-- 1 root root  2328 Oct 17 14:52  fill_nan.py\n","drwxr-xr-x 2 root root  4096 Oct 17 14:52  .idea\n","drwxr-xr-x 2 root root  4096 Oct 17 14:52  img\n","drwxr-xr-x 2 root root  4096 Oct 17 14:52  .ipynb_checkpoints\n","-rw-r--r-- 1 root root  3972 Oct 17 15:18  run_sh.ipynb\n","-rw-r--r-- 1 root root  2859 Oct 17 14:52  tfidf_lr_stack.py\n","-rw-r--r-- 1 root root  3563 Oct 17 14:52  xgb_ens.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sLVM6OlfWFzf","colab_type":"code","outputId":"aa0ccc62-ae6b-456a-d454-76143e9432af","executionInfo":{"status":"ok","timestamp":1571326649207,"user_tz":-480,"elapsed":119295,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":558}},"source":["# 作者将三个属性中为0（代表未知）的数据进行处理，通过不为0的数据使用logistic regression进行预测后填充\n","# query的特征表示使用TF-IDF\n","# 处理完的文件为all_v2.csv\n","import pandas as pd\n","import numpy as np\n","import jieba\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","#filter warning\n","from warnings import simplefilter\n","# ignore all future warnings\n","simplefilter(action='ignore', category=FutureWarning)\n","\n","# 读取原始数据，只取前1w条\n","df_tr = pd.read_csv('./data/train.csv', sep=\"###__###\", header=None, nrows=10000)\n","df_tr.columns = ['ID', 'Age', 'Gender', 'Education', 'query']\n","df_te = pd.read_csv('./data/test.csv', sep=\"###__###\", header=None, nrows=10000)\n","df_te.columns = ['ID', 'query']\n","print(df_tr.shape)\n","print(df_te.shape)\n","\n","df_all = df_tr\n","for lb in ['Education', 'Age', 'Gender']:\n","    df_all[lb] = df_all[lb] - 1\n","    print(df_all.iloc[:10000][lb].value_counts())\n","\n","\n","class Tokenizer:\n","    def __init__(self):\n","        self.n = 0\n","\n","    def __call__(self, line, *args, **kwargs):\n","        tokens = []\n","        for query in line.split('\\t'):\n","            words = [word for word in jieba.cut(query)]\n","            for gram in [1, 2]:\n","                for i in range(len(words) - gram + 1):\n","                    tokens += ['_*_'.join(words[i:i+gram])]\n","        if np.random.rand() < 0.00001:\n","            print(line)\n","            print('='*20)\n","            print(tokens)\n","        self.n += 1\n","        if self.n % 1000 == 0:\n","            print(self.n, end=' ')\n","        return tokens\n","\n","\n","tfv = TfidfVectorizer(tokenizer=Tokenizer(), min_df=3, max_df=0.95, sublinear_tf=True)\n","X_sp = tfv.fit_transform(df_all['query'])\n","print(len(tfv.vocabulary_))\n","X_all = X_sp\n","\n","lb = 'Education'\n","idx = 3\n","tr = np.where(df_all[lb] != -1)[0]\n","va = np.where(df_all[lb] == -1)[0]\n","df_all.iloc[va, idx] = \\\n","    LogisticRegression(C=1).fit(X_all[tr], df_all.iloc[tr, idx]).predict(X_all[va])\n","\n","lb = 'Age'\n","idx = 1\n","tr = np.where(df_all[lb] != -1)[0]\n","va = np.where(df_all[lb] == -1)[0]\n","df_all.iloc[va, idx] = \\\n","    LogisticRegression(C=2).fit(X_all[tr], df_all.iloc[tr, idx]).predict(X_all[va])\n","\n","lb = 'Gender'\n","idx = 2\n","tr = np.where(df_all[lb]!=-1)[0]\n","va = np.where(df_all[lb]==-1)[0]\n","df_all.iloc[va,idx] = \\\n","    LogisticRegression(C=2).fit(X_all[tr], df_all.iloc[tr, idx]).predict(X_all[va])\n","\n","df_all = pd.concat([df_all, df_te]).fillna(0)\n","df_all.to_csv('./data/all_v2.csv', index=None, encoding='utf8')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  from ipykernel import kernelapp as app\n","Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n"],"name":"stderr"},{"output_type":"stream","text":["(10000, 5)\n","(10000, 2)\n"," 4    3764\n"," 3    2804\n"," 2    1869\n","-1     929\n"," 5     540\n"," 1      55\n"," 0      39\n","Name: Education, dtype: int64\n"," 0    3920\n"," 1    2693\n"," 2    1819\n"," 3    1036\n"," 4     314\n","-1     173\n"," 5      45\n","Name: Age, dtype: int64\n"," 0    5720\n"," 1    4048\n","-1     232\n","Name: Gender, dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["Loading model cost 0.762 seconds.\n","Prefix dict has been built succesfully.\n"],"name":"stderr"},{"output_type":"stream","text":["1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 240899\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_TggKtmSWF4g","colab_type":"code","outputId":"af6608a0-9fb7-4f4a-d541-6919d211b759","executionInfo":{"status":"ok","timestamp":1571328495188,"user_tz":-480,"elapsed":449567,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":390}},"source":["# 训练doc2vec模型，dm和dbow都进行了训练\n","import pandas as pd\n","import numpy as np\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","# ********************************************************************************\n","# =========================================== #\n","# 对query进行分词, 保存为query_cut.csv文件。     #\n","# 该过程较为耗时，无需反复执行，运行一次后即可注释掉 #\n","# 再次使用直接读取                              #\n","# =========================================== #\n","# df_query = pd.read_csv('./data/all_v2.csv', usecols=['query'], encoding='utf-8')\n","# rows = []\n","# for i, line in enumerate(df_query.iloc[:10000]['query']):\n","#     words = []\n","#     row = {}\n","#     for query in line.split('\\t'):\n","#         words.extend(list(jieba.cut(query)))\n","#     row['tag'] = i\n","#     row['query_cut'] = words\n","#     rows.append(row)\n","# df_query_cut = pd.DataFrame(rows)\n","# df_query_cut.to_csv('./data/query_cut.csv', index=None, encoding='utf8')\n","# ***********************************************************************************\n","\n","df_query_cut = pd.read_csv('./data/query_cut.csv', encoding='utf-8')\n","query_tagged = df_query_cut.apply(\n","    lambda line: TaggedDocument(words=line['query_cut'], tags=[line['tag']]), axis=1)\n","\n","df_lb = pd.read_csv('./data/all_v2.csv',\n","                    usecols=['Education', 'Age', 'Gender'], nrows=10000)\n","ys = {}\n","for lb in ['Education', 'Age', 'Gender']:\n","    ys[lb] = np.array(df_lb[lb])\n","\n","# -------------------train dbow doc2vec---------------------------------------------\n","dbow_model = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=3,\n","                     window=30, sample=1e-5, workers=8, alpha=0.025, min_alpha=0.025)\n","dbow_model.build_vocab(query_tagged)\n","\n","for i in range(2):\n","    print('pass:', i + 1)\n","    dbow_model.train(query_tagged, total_examples=dbow_model.corpus_count, epochs=dbow_model.epochs)\n","    X_d2v = np.array([dbow_model.docvecs[i] for i in range(10000)])\n","    for lb in ['Education', 'Age', 'Gender']:\n","        scores = cross_val_score(LogisticRegression(C=3), X_d2v, ys[lb], cv=5)\n","        print('dbow', lb, scores, np.mean(scores))\n","dbow_model.save('./data/dbow_model.model')\n","\n","print('='*20)\n","\n","# -------------------train dm doc2vec---------------------------------------------\n","dm_model = Doc2Vec(dm=1, vector_size=300, negative=5, hs=0, min_count=3,\n","                   window=10, sample=1e-5, workers=8, alpha=0.025, min_alpha=0.025)\n","dm_model.build_vocab(query_tagged)\n","\n","for i in range(2):\n","    print('pass:', i + 1)\n","    dm_model.train(query_tagged, total_examples=dm_model.corpus_count, epochs=dm_model.epochs)\n","    X_d2v = np.array([dm_model.docvecs[i] for i in range(10000)])\n","    for lb in ['Education', 'Age', 'Gender']:\n","        scores = cross_val_score(LogisticRegression(C=3), X_d2v, ys[lb], cv=5)\n","        print('dm', lb, scores, np.mean(scores))\n","dm_model.save('./data/dm_model.model')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["pass: 1\n","dbow Education [0.56821589 0.58170915 0.556      0.564      0.56706707] 0.5673984209096654\n","dbow Age [0.51998002 0.51574213 0.51524238 0.51525763 0.5092639 ] 0.515097210476864\n","dbow Gender [0.794  0.791  0.782  0.8005 0.7835] 0.7902\n","pass: 2\n","dbow Education [0.56571714 0.56021989 0.559      0.5545     0.57607608] 0.5631026215120668\n","dbow Age [0.51848152 0.51424288 0.50524738 0.52576288 0.52228343] 0.5172036159865019\n","dbow Gender [0.799  0.799  0.7885 0.8095 0.7875] 0.7967\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["====================\n","pass: 1\n","dm Education [0.55722139 0.55922039 0.541      0.5595     0.55055055] 0.5534984659321991\n","dm Age [0.500999   0.49375312 0.50974513 0.50275138 0.48923385] 0.49929649566751444\n","dm Gender [0.778  0.779  0.762  0.778  0.7725] 0.7739\n","pass: 2\n","dm Education [0.55322339 0.56121939 0.5575     0.56       0.55605606] 0.5575997669333501\n","dm Age [0.50849151 0.49175412 0.50924538 0.49974987 0.51677516] 0.5052032092845937\n","dm Gender [0.781 0.78  0.78  0.786 0.777] 0.7808\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ctRZn4JGWF7v","colab_type":"code","outputId":"c340c98c-b547-4412-f407-2f5beeb025da","executionInfo":{"status":"ok","timestamp":1571328624893,"user_tz":-480,"elapsed":98431,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":840}},"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import KFold\n","\n","\n","# -------------定义评估函数---------------\n","def myAcc(y_true, y_pred):\n","    y_pred = np.argmax(y_pred, axis=1)\n","    return np.mean(y_true == y_pred)\n","\n","\n","# load data\n","df_all = pd.read_csv('./data/all_v2.csv', encoding='utf-8', nrows=10000)\n","ys = {}\n","for lb in ['Education', 'Age', 'Gender']:\n","    ys[lb] = np.array(df_all[lb])\n","\n","# ********************************************************************************\n","# ================================================ #\n","# 对query使用TF-IDF进行表示，保存为tfidf_1w.feat文件.  #\n","# 该过程较为耗时，无需反复执行，运行一次后即可注释掉      #\n","# 再次使用直接用pickle读取                            #\n","# ================================================ #\n","# class Tokenizer:\n","#     def __init__(self):\n","#         self.n = 0\n","#\n","#     def __call__(self, line, *args, **kwargs):\n","#         tokens = []\n","#         for query in line.split('\\t'):\n","#             words = [word for word in jieba.cut(query)]\n","#             for gram in [1, 2]:\n","#                 for i in range(len(words) - gram + 1):\n","#                     tokens += ['_*_'.join(words[i:i+gram])]\n","#         self.n += 1\n","#         if self.n % 1000 == 0:\n","#             print(self.n)\n","#         return tokens\n","#\n","#\n","# tfv = TfidfVectorizer(tokenizer=Tokenizer(), min_df=3, max_df=0.95, sublinear_tf=True)\n","# X_sp = tfv.fit_transform(df_all['query'])\n","# pickle.dump(X_sp, open('./data/tfidf_1w.pkl', 'wb'))\n","# ********************************************************************************\n","\n","X_sp = pickle.load(open('./data/tfidf_1w.feat', 'rb'))\n","df_stack = pd.DataFrame(index=range(len(df_all)))\n","\n","# -----------------------stack for education/age/gender------------------\n","for lb in ['Education', 'Age', 'Gender']:\n","    print(lb)\n","    TR = 8000\n","    num_class = len(pd.value_counts(ys[lb]))\n","    n = 5\n","\n","    X = X_sp[:TR]\n","    y = ys[lb][:TR]\n","    X_te = X_sp[TR:]\n","    y_te = ys[lb][TR:]\n","\n","    stack = np.zeros((X.shape[0], num_class))\n","    stack_te = np.zeros((X_te.shape[0], num_class))\n","\n","    kfold = KFold(n_splits=n, random_state=2019)\n","    for i, (tr, va) in enumerate(kfold.split(X)):\n","        print('stack:%d/%d' % (i + 1, n))\n","        clf = LogisticRegression(C=3)\n","        clf.fit(X[tr], y[tr])\n","        y_pred_va = clf.predict_proba(X[va])\n","        y_pred_te = clf.predict_proba(X_te)\n","        print('va acc:', myAcc(y[va], y_pred_va))\n","        print('te acc:', myAcc(y_te, y_pred_te))\n","        stack[va] += y_pred_va\n","        stack_te += y_pred_te\n","    stack_te /= n\n","    stack_all = np.vstack([stack, stack_te])\n","    for i in range(stack_all.shape[1]):\n","        df_stack['tfidf_{}_{}'.format(lb, i)] = stack_all[:, i]\n","\n","df_stack.to_csv('./data/tfidf_stack_1w.csv', index=None, encoding='utf-8')\n","print('done!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Education\n","stack:1/5\n","va acc: 0.605\n","te acc: 0.635\n","stack:2/5\n","va acc: 0.64625\n","te acc: 0.6295\n","stack:3/5\n","va acc: 0.6175\n","te acc: 0.6355\n","stack:4/5\n","va acc: 0.625625\n","te acc: 0.6275\n","stack:5/5\n","va acc: 0.6125\n","te acc: 0.632\n","Age\n","stack:1/5\n","va acc: 0.535\n","te acc: 0.572\n","stack:2/5\n","va acc: 0.56625\n","te acc: 0.5645\n","stack:3/5\n","va acc: 0.56\n","te acc: 0.5575\n","stack:4/5\n","va acc: 0.545\n","te acc: 0.5705\n","stack:5/5\n","va acc: 0.558125\n","te acc: 0.5705\n","Gender\n","stack:1/5\n","va acc: 0.821875\n","te acc: 0.8045\n","stack:2/5\n","va acc: 0.824375\n","te acc: 0.8075\n","stack:3/5\n","va acc: 0.79875\n","te acc: 0.809\n","stack:4/5\n","va acc: 0.823125\n","te acc: 0.809\n","stack:5/5\n","va acc: 0.81625\n","te acc: 0.8135\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kj8dFuuZWGG0","colab_type":"code","outputId":"d5e1592a-f2ee-4258-c392-9b13816d3823","executionInfo":{"status":"ok","timestamp":1571328700186,"user_tz":-480,"elapsed":67889,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import KFold\n","from gensim.models import Doc2Vec\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","def myAcc(y_true, y_pred):\n","    y_pred = np.argmax(y_pred, axis=1)\n","    return np.mean(y_true == y_pred)\n","\n","\n","df_all = pd.read_csv('./data/all_v2.csv', usecols=['ID', 'Education', 'Age', 'Gender'], nrows=10000)\n","ys = {}\n","for label in ['Education', 'Age', 'Gender']:\n","    ys[label] = np.array(df_all[label])\n","\n","model = Doc2Vec.load('./data/dbow_model.model')\n","X_sp = np.array([model.docvecs[i] for i in range(len(df_all))])\n","\n","df_stack = pd.DataFrame(index=range(len(df_all)))\n","TR = 8000\n","n = 5\n","X = X_sp[:TR]\n","X_te = X_sp[TR:]\n","\n","for i, lb in enumerate(['Education', 'Age', 'Gender']):\n","    print(lb)\n","    num_class = len(pd.value_counts(ys[lb]))\n","    y = ys[lb][:TR]\n","    y_te = ys[lb][TR:]\n","\n","    stack = np.zeros((X.shape[0], num_class))\n","    stack_te = np.zeros((X_te.shape[0], num_class))\n","\n","    nn_model = Sequential()\n","    nn_model.add(Dense(300, input_shape=(X.shape[1],)))\n","    nn_model.add(Dropout(0.1))\n","    nn_model.add(Activation('tanh'))\n","    nn_model.add(Dense(num_class))\n","    nn_model.add(Activation('softmax'))\n","\n","    nn_model.compile(\n","        optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    kfold = KFold(n_splits=n, random_state=2019)\n","    for i, (tr, va) in enumerate(kfold.split(X)):\n","        print('stack:{}/{}'.format(i + 1, n))\n","        nb_classes = num_class\n","        X_train = X[tr].astype('float32')\n","        y_train = y[tr]\n","        Y_train = to_categorical(y_train, num_classes=nb_classes)\n","        X_test = X_te.astype('float32')\n","        y_test = y_te\n","        Y_test = to_categorical(y_test, num_classes=nb_classes)\n","\n","        history = nn_model.fit(X_train, Y_train,\n","                               shuffle=True, batch_size=128, epochs=16, verbose=2,\n","                               validation_data=(X_test, Y_test))\n","\n","        y_pred_va = nn_model.predict_proba(X[va])\n","        y_pred_te = nn_model.predict_proba(X_te)\n","        print('va acc: ', myAcc(y[va], y_pred_va))\n","        print('te acc: ', myAcc(y_te, y_pred_te))\n","        stack[va] += y_pred_va\n","        stack_te += y_pred_te\n","    stack_te /= n\n","    stack_all = np.vstack([stack, stack_te])\n","    for i in range(stack_all.shape[1]):\n","        df_stack['dbow_nn_{}_{}'.format(lb, i)] = stack_all[:, i]\n","\n","df_stack.to_csv('./data/dbow_stack_1w.csv', index=None, encoding='utf-8')\n","print('done!')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["Education\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","stack:1/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 1s - loss: 1.8186 - acc: 0.1883 - val_loss: 1.8186 - val_acc: 0.1835\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.8069 - acc: 0.1925 - val_loss: 1.8085 - val_acc: 0.1875\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.7983 - acc: 0.1992 - val_loss: 1.7984 - val_acc: 0.1970\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.7883 - acc: 0.2158 - val_loss: 1.7883 - val_acc: 0.2055\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.7778 - acc: 0.2183 - val_loss: 1.7781 - val_acc: 0.2110\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.7674 - acc: 0.2277 - val_loss: 1.7679 - val_acc: 0.2220\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.7618 - acc: 0.2345 - val_loss: 1.7577 - val_acc: 0.2330\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.7511 - acc: 0.2458 - val_loss: 1.7476 - val_acc: 0.2460\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.7402 - acc: 0.2489 - val_loss: 1.7375 - val_acc: 0.2515\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.7308 - acc: 0.2655 - val_loss: 1.7275 - val_acc: 0.2570\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.7223 - acc: 0.2684 - val_loss: 1.7175 - val_acc: 0.2665\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.7118 - acc: 0.2856 - val_loss: 1.7077 - val_acc: 0.2735\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.7029 - acc: 0.2931 - val_loss: 1.6979 - val_acc: 0.2825\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.6920 - acc: 0.2994 - val_loss: 1.6882 - val_acc: 0.2925\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.6826 - acc: 0.3094 - val_loss: 1.6785 - val_acc: 0.3025\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.6730 - acc: 0.3219 - val_loss: 1.6691 - val_acc: 0.3110\n","va acc:  0.318125\n","te acc:  0.311\n","stack:2/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.6656 - acc: 0.3256 - val_loss: 1.6597 - val_acc: 0.3225\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.6546 - acc: 0.3381 - val_loss: 1.6504 - val_acc: 0.3295\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.6473 - acc: 0.3402 - val_loss: 1.6412 - val_acc: 0.3370\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.6397 - acc: 0.3533 - val_loss: 1.6322 - val_acc: 0.3415\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.6292 - acc: 0.3584 - val_loss: 1.6233 - val_acc: 0.3475\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.6220 - acc: 0.3673 - val_loss: 1.6145 - val_acc: 0.3580\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.6134 - acc: 0.3602 - val_loss: 1.6059 - val_acc: 0.3630\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.6045 - acc: 0.3736 - val_loss: 1.5974 - val_acc: 0.3680\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.5960 - acc: 0.3817 - val_loss: 1.5890 - val_acc: 0.3770\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.5880 - acc: 0.3833 - val_loss: 1.5807 - val_acc: 0.3845\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.5825 - acc: 0.3866 - val_loss: 1.5726 - val_acc: 0.3890\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.5727 - acc: 0.4003 - val_loss: 1.5646 - val_acc: 0.3940\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.5643 - acc: 0.4011 - val_loss: 1.5568 - val_acc: 0.4010\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.5580 - acc: 0.4058 - val_loss: 1.5491 - val_acc: 0.4045\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.5490 - acc: 0.4089 - val_loss: 1.5415 - val_acc: 0.4120\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.5452 - acc: 0.4091 - val_loss: 1.5341 - val_acc: 0.4130\n","va acc:  0.418125\n","te acc:  0.413\n","stack:3/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.5406 - acc: 0.4238 - val_loss: 1.5268 - val_acc: 0.4200\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.5339 - acc: 0.4184 - val_loss: 1.5196 - val_acc: 0.4215\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.5256 - acc: 0.4236 - val_loss: 1.5126 - val_acc: 0.4250\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.5196 - acc: 0.4259 - val_loss: 1.5057 - val_acc: 0.4275\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.5140 - acc: 0.4289 - val_loss: 1.4989 - val_acc: 0.4290\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.5047 - acc: 0.4336 - val_loss: 1.4923 - val_acc: 0.4340\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.5002 - acc: 0.4327 - val_loss: 1.4857 - val_acc: 0.4365\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.4932 - acc: 0.4338 - val_loss: 1.4793 - val_acc: 0.4400\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.4889 - acc: 0.4411 - val_loss: 1.4731 - val_acc: 0.4450\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.4807 - acc: 0.4433 - val_loss: 1.4669 - val_acc: 0.4480\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.4750 - acc: 0.4427 - val_loss: 1.4609 - val_acc: 0.4505\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.4690 - acc: 0.4494 - val_loss: 1.4550 - val_acc: 0.4510\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.4618 - acc: 0.4530 - val_loss: 1.4492 - val_acc: 0.4515\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.4567 - acc: 0.4542 - val_loss: 1.4435 - val_acc: 0.4510\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.4518 - acc: 0.4500 - val_loss: 1.4379 - val_acc: 0.4515\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.4460 - acc: 0.4580 - val_loss: 1.4324 - val_acc: 0.4540\n","va acc:  0.460625\n","te acc:  0.454\n","stack:4/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.4401 - acc: 0.4584 - val_loss: 1.4271 - val_acc: 0.4560\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.4347 - acc: 0.4633 - val_loss: 1.4219 - val_acc: 0.4550\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.4288 - acc: 0.4583 - val_loss: 1.4167 - val_acc: 0.4540\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.4237 - acc: 0.4639 - val_loss: 1.4117 - val_acc: 0.4565\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.4219 - acc: 0.4641 - val_loss: 1.4068 - val_acc: 0.4590\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.4129 - acc: 0.4655 - val_loss: 1.4019 - val_acc: 0.4585\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.4105 - acc: 0.4647 - val_loss: 1.3972 - val_acc: 0.4580\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.4074 - acc: 0.4681 - val_loss: 1.3925 - val_acc: 0.4595\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.4023 - acc: 0.4613 - val_loss: 1.3880 - val_acc: 0.4615\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.3977 - acc: 0.4666 - val_loss: 1.3835 - val_acc: 0.4615\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.3916 - acc: 0.4681 - val_loss: 1.3791 - val_acc: 0.4605\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.3874 - acc: 0.4780 - val_loss: 1.3748 - val_acc: 0.4615\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.3856 - acc: 0.4666 - val_loss: 1.3706 - val_acc: 0.4630\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.3795 - acc: 0.4692 - val_loss: 1.3665 - val_acc: 0.4655\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.3755 - acc: 0.4773 - val_loss: 1.3624 - val_acc: 0.4665\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.3734 - acc: 0.4752 - val_loss: 1.3584 - val_acc: 0.4660\n","va acc:  0.463125\n","te acc:  0.466\n","stack:5/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.3722 - acc: 0.4692 - val_loss: 1.3545 - val_acc: 0.4665\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.3642 - acc: 0.4725 - val_loss: 1.3507 - val_acc: 0.4680\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.3649 - acc: 0.4664 - val_loss: 1.3469 - val_acc: 0.4695\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.3608 - acc: 0.4697 - val_loss: 1.3432 - val_acc: 0.4700\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.3545 - acc: 0.4719 - val_loss: 1.3396 - val_acc: 0.4705\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.3542 - acc: 0.4692 - val_loss: 1.3361 - val_acc: 0.4720\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.3503 - acc: 0.4730 - val_loss: 1.3326 - val_acc: 0.4735\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.3453 - acc: 0.4728 - val_loss: 1.3292 - val_acc: 0.4750\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.3445 - acc: 0.4758 - val_loss: 1.3258 - val_acc: 0.4760\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.3373 - acc: 0.4764 - val_loss: 1.3225 - val_acc: 0.4770\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.3347 - acc: 0.4755 - val_loss: 1.3193 - val_acc: 0.4780\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.3328 - acc: 0.4769 - val_loss: 1.3161 - val_acc: 0.4780\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.3290 - acc: 0.4786 - val_loss: 1.3130 - val_acc: 0.4785\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.3301 - acc: 0.4756 - val_loss: 1.3100 - val_acc: 0.4790\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.3234 - acc: 0.4758 - val_loss: 1.3070 - val_acc: 0.4780\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.3220 - acc: 0.4844 - val_loss: 1.3040 - val_acc: 0.4780\n","va acc:  0.494375\n","te acc:  0.478\n","Age\n","stack:1/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.8440 - acc: 0.1591 - val_loss: 1.8348 - val_acc: 0.1540\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.8359 - acc: 0.1645 - val_loss: 1.8275 - val_acc: 0.1605\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.8295 - acc: 0.1728 - val_loss: 1.8202 - val_acc: 0.1655\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.8225 - acc: 0.1767 - val_loss: 1.8129 - val_acc: 0.1715\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.8135 - acc: 0.1764 - val_loss: 1.8055 - val_acc: 0.1795\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.8072 - acc: 0.1873 - val_loss: 1.7981 - val_acc: 0.1880\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.7972 - acc: 0.1952 - val_loss: 1.7908 - val_acc: 0.1955\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.7912 - acc: 0.2034 - val_loss: 1.7835 - val_acc: 0.1995\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.7842 - acc: 0.2042 - val_loss: 1.7762 - val_acc: 0.2040\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.7777 - acc: 0.2095 - val_loss: 1.7690 - val_acc: 0.2125\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.7708 - acc: 0.2198 - val_loss: 1.7618 - val_acc: 0.2200\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.7644 - acc: 0.2248 - val_loss: 1.7547 - val_acc: 0.2240\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.7543 - acc: 0.2327 - val_loss: 1.7476 - val_acc: 0.2305\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.7485 - acc: 0.2328 - val_loss: 1.7407 - val_acc: 0.2370\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.7427 - acc: 0.2395 - val_loss: 1.7338 - val_acc: 0.2380\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.7343 - acc: 0.2478 - val_loss: 1.7270 - val_acc: 0.2445\n","va acc:  0.26125\n","te acc:  0.2445\n","stack:2/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.7260 - acc: 0.2467 - val_loss: 1.7202 - val_acc: 0.2510\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.7186 - acc: 0.2562 - val_loss: 1.7135 - val_acc: 0.2515\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.7120 - acc: 0.2609 - val_loss: 1.7070 - val_acc: 0.2595\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.7049 - acc: 0.2709 - val_loss: 1.7005 - val_acc: 0.2620\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.6995 - acc: 0.2711 - val_loss: 1.6941 - val_acc: 0.2680\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.6912 - acc: 0.2806 - val_loss: 1.6877 - val_acc: 0.2755\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.6848 - acc: 0.2834 - val_loss: 1.6815 - val_acc: 0.2795\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.6790 - acc: 0.2928 - val_loss: 1.6754 - val_acc: 0.2850\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.6727 - acc: 0.2973 - val_loss: 1.6694 - val_acc: 0.2900\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.6657 - acc: 0.2989 - val_loss: 1.6635 - val_acc: 0.2960\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.6600 - acc: 0.3086 - val_loss: 1.6577 - val_acc: 0.3040\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.6563 - acc: 0.3058 - val_loss: 1.6519 - val_acc: 0.3055\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.6494 - acc: 0.3195 - val_loss: 1.6463 - val_acc: 0.3125\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.6421 - acc: 0.3208 - val_loss: 1.6408 - val_acc: 0.3155\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.6372 - acc: 0.3267 - val_loss: 1.6353 - val_acc: 0.3200\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.6314 - acc: 0.3308 - val_loss: 1.6300 - val_acc: 0.3250\n","va acc:  0.335\n","te acc:  0.325\n","stack:3/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.6281 - acc: 0.3359 - val_loss: 1.6247 - val_acc: 0.3290\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.6213 - acc: 0.3370 - val_loss: 1.6196 - val_acc: 0.3315\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.6162 - acc: 0.3403 - val_loss: 1.6145 - val_acc: 0.3385\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.6081 - acc: 0.3487 - val_loss: 1.6095 - val_acc: 0.3420\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.6042 - acc: 0.3444 - val_loss: 1.6047 - val_acc: 0.3455\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.6007 - acc: 0.3461 - val_loss: 1.5999 - val_acc: 0.3490\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.5939 - acc: 0.3564 - val_loss: 1.5952 - val_acc: 0.3525\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.5908 - acc: 0.3548 - val_loss: 1.5906 - val_acc: 0.3565\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.5859 - acc: 0.3620 - val_loss: 1.5860 - val_acc: 0.3580\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.5808 - acc: 0.3642 - val_loss: 1.5816 - val_acc: 0.3600\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.5749 - acc: 0.3694 - val_loss: 1.5773 - val_acc: 0.3630\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.5735 - acc: 0.3666 - val_loss: 1.5730 - val_acc: 0.3630\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.5689 - acc: 0.3673 - val_loss: 1.5688 - val_acc: 0.3650\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.5618 - acc: 0.3781 - val_loss: 1.5647 - val_acc: 0.3650\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.5594 - acc: 0.3705 - val_loss: 1.5607 - val_acc: 0.3670\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.5543 - acc: 0.3744 - val_loss: 1.5567 - val_acc: 0.3710\n","va acc:  0.38375\n","te acc:  0.371\n","stack:4/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.5506 - acc: 0.3841 - val_loss: 1.5529 - val_acc: 0.3730\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.5482 - acc: 0.3845 - val_loss: 1.5491 - val_acc: 0.3775\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.5451 - acc: 0.3825 - val_loss: 1.5454 - val_acc: 0.3810\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.5417 - acc: 0.3898 - val_loss: 1.5417 - val_acc: 0.3805\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.5362 - acc: 0.3923 - val_loss: 1.5381 - val_acc: 0.3825\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.5353 - acc: 0.3934 - val_loss: 1.5346 - val_acc: 0.3825\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.5299 - acc: 0.3897 - val_loss: 1.5312 - val_acc: 0.3860\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.5268 - acc: 0.3916 - val_loss: 1.5278 - val_acc: 0.3855\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.5217 - acc: 0.3948 - val_loss: 1.5245 - val_acc: 0.3865\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.5196 - acc: 0.3950 - val_loss: 1.5212 - val_acc: 0.3870\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.5166 - acc: 0.4006 - val_loss: 1.5180 - val_acc: 0.3885\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.5134 - acc: 0.3998 - val_loss: 1.5149 - val_acc: 0.3900\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.5105 - acc: 0.3958 - val_loss: 1.5118 - val_acc: 0.3900\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.5066 - acc: 0.4005 - val_loss: 1.5088 - val_acc: 0.3915\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.5029 - acc: 0.3984 - val_loss: 1.5058 - val_acc: 0.3900\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.4986 - acc: 0.4058 - val_loss: 1.5029 - val_acc: 0.3915\n","va acc:  0.384375\n","te acc:  0.3915\n","stack:5/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.5013 - acc: 0.3959 - val_loss: 1.5001 - val_acc: 0.3925\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.4987 - acc: 0.4014 - val_loss: 1.4973 - val_acc: 0.3940\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.4944 - acc: 0.3997 - val_loss: 1.4945 - val_acc: 0.3940\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.4919 - acc: 0.4011 - val_loss: 1.4918 - val_acc: 0.3950\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.4880 - acc: 0.3980 - val_loss: 1.4892 - val_acc: 0.3965\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.4870 - acc: 0.4014 - val_loss: 1.4866 - val_acc: 0.3980\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.4835 - acc: 0.4053 - val_loss: 1.4840 - val_acc: 0.3970\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.4782 - acc: 0.4080 - val_loss: 1.4815 - val_acc: 0.3990\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.4783 - acc: 0.4083 - val_loss: 1.4790 - val_acc: 0.3995\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.4757 - acc: 0.4080 - val_loss: 1.4765 - val_acc: 0.3995\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.4736 - acc: 0.4053 - val_loss: 1.4741 - val_acc: 0.3995\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.4693 - acc: 0.4072 - val_loss: 1.4717 - val_acc: 0.4000\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.4681 - acc: 0.4083 - val_loss: 1.4694 - val_acc: 0.4010\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.4650 - acc: 0.4133 - val_loss: 1.4671 - val_acc: 0.4010\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.4626 - acc: 0.4092 - val_loss: 1.4648 - val_acc: 0.4000\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.4616 - acc: 0.4111 - val_loss: 1.4626 - val_acc: 0.4000\n","va acc:  0.439375\n","te acc:  0.4\n","Gender\n","stack:1/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.7660 - acc: 0.4150 - val_loss: 0.7697 - val_acc: 0.3965\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.7647 - acc: 0.4152 - val_loss: 0.7665 - val_acc: 0.4005\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.7615 - acc: 0.4180 - val_loss: 0.7634 - val_acc: 0.4040\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.7600 - acc: 0.4261 - val_loss: 0.7603 - val_acc: 0.4060\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.7555 - acc: 0.4356 - val_loss: 0.7572 - val_acc: 0.4140\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.7518 - acc: 0.4403 - val_loss: 0.7543 - val_acc: 0.4170\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.7501 - acc: 0.4405 - val_loss: 0.7514 - val_acc: 0.4240\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.7472 - acc: 0.4434 - val_loss: 0.7486 - val_acc: 0.4360\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.7447 - acc: 0.4473 - val_loss: 0.7458 - val_acc: 0.4390\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.7411 - acc: 0.4575 - val_loss: 0.7431 - val_acc: 0.4430\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.7399 - acc: 0.4606 - val_loss: 0.7405 - val_acc: 0.4540\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.7375 - acc: 0.4686 - val_loss: 0.7379 - val_acc: 0.4540\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.7338 - acc: 0.4734 - val_loss: 0.7353 - val_acc: 0.4590\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.7330 - acc: 0.4758 - val_loss: 0.7328 - val_acc: 0.4635\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.7297 - acc: 0.4834 - val_loss: 0.7303 - val_acc: 0.4695\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.7268 - acc: 0.4870 - val_loss: 0.7279 - val_acc: 0.4770\n","va acc:  0.500625\n","te acc:  0.477\n","stack:2/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.7223 - acc: 0.4973 - val_loss: 0.7256 - val_acc: 0.4870\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.7198 - acc: 0.5050 - val_loss: 0.7233 - val_acc: 0.4895\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.7176 - acc: 0.5003 - val_loss: 0.7210 - val_acc: 0.4905\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.7154 - acc: 0.5123 - val_loss: 0.7188 - val_acc: 0.4950\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.7164 - acc: 0.5100 - val_loss: 0.7166 - val_acc: 0.5020\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.7127 - acc: 0.5198 - val_loss: 0.7144 - val_acc: 0.5060\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.7091 - acc: 0.5245 - val_loss: 0.7123 - val_acc: 0.5100\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.7078 - acc: 0.5247 - val_loss: 0.7102 - val_acc: 0.5145\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.7070 - acc: 0.5330 - val_loss: 0.7081 - val_acc: 0.5185\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.7028 - acc: 0.5355 - val_loss: 0.7060 - val_acc: 0.5225\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.7010 - acc: 0.5381 - val_loss: 0.7040 - val_acc: 0.5275\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.6999 - acc: 0.5392 - val_loss: 0.7021 - val_acc: 0.5310\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.6982 - acc: 0.5461 - val_loss: 0.7001 - val_acc: 0.5370\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.6982 - acc: 0.5395 - val_loss: 0.6982 - val_acc: 0.5410\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.6944 - acc: 0.5537 - val_loss: 0.6963 - val_acc: 0.5445\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.6913 - acc: 0.5573 - val_loss: 0.6944 - val_acc: 0.5490\n","va acc:  0.54875\n","te acc:  0.549\n","stack:3/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.6876 - acc: 0.5600 - val_loss: 0.6925 - val_acc: 0.5505\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.6872 - acc: 0.5586 - val_loss: 0.6906 - val_acc: 0.5520\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.6873 - acc: 0.5655 - val_loss: 0.6887 - val_acc: 0.5530\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.6833 - acc: 0.5678 - val_loss: 0.6869 - val_acc: 0.5535\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.6813 - acc: 0.5763 - val_loss: 0.6851 - val_acc: 0.5575\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.6801 - acc: 0.5714 - val_loss: 0.6833 - val_acc: 0.5605\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.6762 - acc: 0.5819 - val_loss: 0.6816 - val_acc: 0.5665\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.6759 - acc: 0.5775 - val_loss: 0.6799 - val_acc: 0.5675\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.6759 - acc: 0.5827 - val_loss: 0.6781 - val_acc: 0.5705\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.6737 - acc: 0.5828 - val_loss: 0.6764 - val_acc: 0.5740\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.6696 - acc: 0.5891 - val_loss: 0.6748 - val_acc: 0.5740\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.6692 - acc: 0.5872 - val_loss: 0.6731 - val_acc: 0.5770\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.6683 - acc: 0.5941 - val_loss: 0.6715 - val_acc: 0.5800\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.6672 - acc: 0.5933 - val_loss: 0.6699 - val_acc: 0.5830\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.6649 - acc: 0.5962 - val_loss: 0.6683 - val_acc: 0.5865\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.6635 - acc: 0.5981 - val_loss: 0.6667 - val_acc: 0.5895\n","va acc:  0.60625\n","te acc:  0.5895\n","stack:4/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.6639 - acc: 0.6034 - val_loss: 0.6651 - val_acc: 0.5935\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.6640 - acc: 0.6031 - val_loss: 0.6636 - val_acc: 0.5960\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.6636 - acc: 0.6036 - val_loss: 0.6621 - val_acc: 0.5990\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.6596 - acc: 0.6064 - val_loss: 0.6605 - val_acc: 0.6000\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.6586 - acc: 0.6075 - val_loss: 0.6590 - val_acc: 0.6020\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.6566 - acc: 0.6100 - val_loss: 0.6576 - val_acc: 0.6050\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.6545 - acc: 0.6173 - val_loss: 0.6561 - val_acc: 0.6090\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.6546 - acc: 0.6186 - val_loss: 0.6547 - val_acc: 0.6115\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.6516 - acc: 0.6187 - val_loss: 0.6532 - val_acc: 0.6135\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.6527 - acc: 0.6200 - val_loss: 0.6518 - val_acc: 0.6180\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.6488 - acc: 0.6286 - val_loss: 0.6504 - val_acc: 0.6195\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.6472 - acc: 0.6233 - val_loss: 0.6490 - val_acc: 0.6250\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.6461 - acc: 0.6264 - val_loss: 0.6476 - val_acc: 0.6280\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.6468 - acc: 0.6250 - val_loss: 0.6462 - val_acc: 0.6305\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.6433 - acc: 0.6322 - val_loss: 0.6449 - val_acc: 0.6335\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.6435 - acc: 0.6288 - val_loss: 0.6435 - val_acc: 0.6365\n","va acc:  0.644375\n","te acc:  0.6365\n","stack:5/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.6394 - acc: 0.6348 - val_loss: 0.6421 - val_acc: 0.6375\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.6355 - acc: 0.6441 - val_loss: 0.6408 - val_acc: 0.6380\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.6357 - acc: 0.6423 - val_loss: 0.6395 - val_acc: 0.6405\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.6354 - acc: 0.6472 - val_loss: 0.6381 - val_acc: 0.6400\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.6320 - acc: 0.6473 - val_loss: 0.6368 - val_acc: 0.6420\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.6321 - acc: 0.6461 - val_loss: 0.6355 - val_acc: 0.6425\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.6286 - acc: 0.6511 - val_loss: 0.6343 - val_acc: 0.6445\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.6277 - acc: 0.6494 - val_loss: 0.6330 - val_acc: 0.6450\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.6294 - acc: 0.6506 - val_loss: 0.6317 - val_acc: 0.6460\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.6268 - acc: 0.6536 - val_loss: 0.6305 - val_acc: 0.6485\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.6248 - acc: 0.6592 - val_loss: 0.6292 - val_acc: 0.6525\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.6240 - acc: 0.6569 - val_loss: 0.6280 - val_acc: 0.6530\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.6238 - acc: 0.6559 - val_loss: 0.6268 - val_acc: 0.6535\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.6212 - acc: 0.6641 - val_loss: 0.6256 - val_acc: 0.6560\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.6220 - acc: 0.6620 - val_loss: 0.6244 - val_acc: 0.6565\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.6188 - acc: 0.6656 - val_loss: 0.6232 - val_acc: 0.6575\n","va acc:  0.643125\n","te acc:  0.6575\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RCRPMhNfWGLL","colab_type":"code","outputId":"0886e63b-ddb6-4aab-9cdc-9754f36521b1","executionInfo":{"status":"ok","timestamp":1571328771261,"user_tz":-480,"elapsed":65902,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","import numpy as np\n","from gensim.models import Doc2Vec\n","from sklearn.model_selection import KFold\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","def myAcc(y_true, y_pred):\n","    y_pred = np.argmax(y_pred, axis=1)\n","    return np.mean(y_true == y_pred)\n","\n","\n","df_all = pd.read_csv(\n","    './data/all_v2.csv', usecols=['ID', 'Education', 'Age', 'Gender'], nrows=10000)\n","ys = {}\n","for lb in ['Education', 'Age', 'Gender']:\n","    ys[lb] = np.array(df_all[lb])\n","\n","model = Doc2Vec.load('./data/dm_model.model')\n","X_sp = np.array([model.docvecs[i] for i in range(len(df_all))])\n","\n","df_stack = pd.DataFrame(index=range(len(df_all)))\n","TR = 8000\n","n = 5\n","\n","X = X_sp[:TR]\n","X_te = X_sp[TR:]\n","\n","for i, lb in enumerate(['Education', 'Age', 'Gender']):\n","    print(lb)\n","    num_class = len(pd.value_counts(ys[lb]))\n","    y = ys[lb][:TR]\n","    y_te = ys[lb][TR:]\n","\n","    stack = np.zeros((X.shape[0], num_class))\n","    stack_te = np.zeros((X_te.shape[0], num_class))\n","\n","    nn_model = Sequential()\n","    nn_model.add(Dense(300, input_shape=(X.shape[1], )))\n","    nn_model.add(Dropout(0.1))\n","    nn_model.add(Activation('tanh'))\n","    nn_model.add(Dense(num_class))\n","    nn_model.add(Activation('softmax'))\n","\n","    nn_model.compile(\n","        optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    kfold = KFold(n_splits=n, random_state=2019)\n","    for i, (tr, va) in enumerate(kfold.split(X)):\n","        print('stack:{}/{}'.format(i + 1, n))\n","        X_train = X[tr]\n","        Y_train = to_categorical(y[tr], num_class)\n","        X_test = X_te\n","        Y_test = to_categorical(y_te, num_class)\n","\n","        history = nn_model.fit(X_train, Y_train,\n","                               batch_size=128, epochs=16, shuffle=True, verbose=2,\n","                               validation_data=(X_test, Y_test))\n","        y_pred_va = nn_model.predict_proba(X[va])\n","        y_pred_te = nn_model.predict_proba(X_te)\n","        print('va acc:', myAcc(y[va], y_pred_va))\n","        print('te acc:', myAcc(y_te, y_pred_te))\n","\n","        stack[va] += y_pred_va\n","        stack_te += y_pred_te\n","    stack_te /= n\n","    stack_all = np.vstack([stack, stack_te])\n","    for i in range(stack_all.shape[1]):\n","        df_stack['dm_nn_{}_{}'.format(lb, i)] = stack_all[:, i]\n","df_stack.to_csv('./data/dm_stack_1w.csv', index=None)\n","print('done!')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["Education\n","stack:1/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 2.0044 - acc: 0.1242 - val_loss: 1.9761 - val_acc: 0.1300\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.9855 - acc: 0.1359 - val_loss: 1.9566 - val_acc: 0.1405\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.9651 - acc: 0.1445 - val_loss: 1.9372 - val_acc: 0.1490\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.9466 - acc: 0.1506 - val_loss: 1.9180 - val_acc: 0.1545\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.9283 - acc: 0.1584 - val_loss: 1.8988 - val_acc: 0.1625\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.9104 - acc: 0.1683 - val_loss: 1.8798 - val_acc: 0.1745\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.8887 - acc: 0.1811 - val_loss: 1.8611 - val_acc: 0.1825\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.8741 - acc: 0.1875 - val_loss: 1.8426 - val_acc: 0.1905\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.8531 - acc: 0.2002 - val_loss: 1.8243 - val_acc: 0.2030\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.8439 - acc: 0.2033 - val_loss: 1.8063 - val_acc: 0.2145\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.8273 - acc: 0.2159 - val_loss: 1.7886 - val_acc: 0.2245\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.8043 - acc: 0.2242 - val_loss: 1.7712 - val_acc: 0.2395\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.7908 - acc: 0.2341 - val_loss: 1.7541 - val_acc: 0.2500\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.7749 - acc: 0.2448 - val_loss: 1.7373 - val_acc: 0.2610\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.7596 - acc: 0.2520 - val_loss: 1.7209 - val_acc: 0.2760\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.7427 - acc: 0.2698 - val_loss: 1.7048 - val_acc: 0.2870\n","va acc: 0.265\n","te acc: 0.287\n","stack:2/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.7270 - acc: 0.2672 - val_loss: 1.6891 - val_acc: 0.2995\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.7139 - acc: 0.2848 - val_loss: 1.6737 - val_acc: 0.3080\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.7039 - acc: 0.2892 - val_loss: 1.6586 - val_acc: 0.3135\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.6871 - acc: 0.3019 - val_loss: 1.6439 - val_acc: 0.3230\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.6754 - acc: 0.3061 - val_loss: 1.6296 - val_acc: 0.3300\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.6574 - acc: 0.3152 - val_loss: 1.6156 - val_acc: 0.3360\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.6430 - acc: 0.3275 - val_loss: 1.6019 - val_acc: 0.3425\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.6320 - acc: 0.3333 - val_loss: 1.5885 - val_acc: 0.3525\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.6186 - acc: 0.3445 - val_loss: 1.5755 - val_acc: 0.3605\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.6116 - acc: 0.3473 - val_loss: 1.5628 - val_acc: 0.3675\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.5952 - acc: 0.3578 - val_loss: 1.5504 - val_acc: 0.3735\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.5828 - acc: 0.3567 - val_loss: 1.5384 - val_acc: 0.3785\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.5724 - acc: 0.3677 - val_loss: 1.5267 - val_acc: 0.3835\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.5598 - acc: 0.3752 - val_loss: 1.5153 - val_acc: 0.3905\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.5499 - acc: 0.3791 - val_loss: 1.5041 - val_acc: 0.3965\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.5395 - acc: 0.3844 - val_loss: 1.4933 - val_acc: 0.4015\n","va acc: 0.418125\n","te acc: 0.4015\n","stack:3/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.5308 - acc: 0.3923 - val_loss: 1.4829 - val_acc: 0.4115\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.5194 - acc: 0.3986 - val_loss: 1.4727 - val_acc: 0.4135\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.5085 - acc: 0.4081 - val_loss: 1.4627 - val_acc: 0.4190\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.4980 - acc: 0.4047 - val_loss: 1.4531 - val_acc: 0.4220\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.4878 - acc: 0.4148 - val_loss: 1.4437 - val_acc: 0.4240\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.4800 - acc: 0.4161 - val_loss: 1.4346 - val_acc: 0.4300\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.4738 - acc: 0.4214 - val_loss: 1.4257 - val_acc: 0.4330\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.4686 - acc: 0.4219 - val_loss: 1.4171 - val_acc: 0.4360\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.4549 - acc: 0.4298 - val_loss: 1.4087 - val_acc: 0.4400\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.4476 - acc: 0.4228 - val_loss: 1.4006 - val_acc: 0.4445\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.4415 - acc: 0.4347 - val_loss: 1.3927 - val_acc: 0.4465\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.4321 - acc: 0.4405 - val_loss: 1.3850 - val_acc: 0.4520\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.4213 - acc: 0.4428 - val_loss: 1.3775 - val_acc: 0.4550\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.4164 - acc: 0.4452 - val_loss: 1.3703 - val_acc: 0.4570\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.4096 - acc: 0.4491 - val_loss: 1.3633 - val_acc: 0.4605\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.4016 - acc: 0.4503 - val_loss: 1.3564 - val_acc: 0.4620\n","va acc: 0.475\n","te acc: 0.462\n","stack:4/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.3982 - acc: 0.4545 - val_loss: 1.3497 - val_acc: 0.4650\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.3870 - acc: 0.4620 - val_loss: 1.3433 - val_acc: 0.4675\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.3847 - acc: 0.4558 - val_loss: 1.3370 - val_acc: 0.4685\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.3772 - acc: 0.4650 - val_loss: 1.3309 - val_acc: 0.4740\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.3752 - acc: 0.4591 - val_loss: 1.3249 - val_acc: 0.4765\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.3637 - acc: 0.4667 - val_loss: 1.3191 - val_acc: 0.4785\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.3595 - acc: 0.4695 - val_loss: 1.3135 - val_acc: 0.4815\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.3546 - acc: 0.4744 - val_loss: 1.3080 - val_acc: 0.4820\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.3492 - acc: 0.4727 - val_loss: 1.3027 - val_acc: 0.4825\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.3450 - acc: 0.4733 - val_loss: 1.2976 - val_acc: 0.4845\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.3386 - acc: 0.4731 - val_loss: 1.2925 - val_acc: 0.4865\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.3315 - acc: 0.4859 - val_loss: 1.2877 - val_acc: 0.4865\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.3296 - acc: 0.4844 - val_loss: 1.2829 - val_acc: 0.4865\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.3251 - acc: 0.4870 - val_loss: 1.2783 - val_acc: 0.4885\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.3215 - acc: 0.4834 - val_loss: 1.2738 - val_acc: 0.4890\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.3119 - acc: 0.4844 - val_loss: 1.2694 - val_acc: 0.4925\n","va acc: 0.4875\n","te acc: 0.4925\n","stack:5/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.3085 - acc: 0.4861 - val_loss: 1.2653 - val_acc: 0.4940\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.3040 - acc: 0.4866 - val_loss: 1.2612 - val_acc: 0.4950\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.3004 - acc: 0.4897 - val_loss: 1.2572 - val_acc: 0.4960\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.2973 - acc: 0.4869 - val_loss: 1.2533 - val_acc: 0.4960\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.2925 - acc: 0.4866 - val_loss: 1.2496 - val_acc: 0.4970\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.2848 - acc: 0.4917 - val_loss: 1.2459 - val_acc: 0.4980\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.2853 - acc: 0.4933 - val_loss: 1.2424 - val_acc: 0.4985\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.2780 - acc: 0.5002 - val_loss: 1.2389 - val_acc: 0.5000\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.2777 - acc: 0.4953 - val_loss: 1.2355 - val_acc: 0.5000\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.2717 - acc: 0.4956 - val_loss: 1.2322 - val_acc: 0.5015\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.2654 - acc: 0.5005 - val_loss: 1.2290 - val_acc: 0.5020\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.2637 - acc: 0.5047 - val_loss: 1.2259 - val_acc: 0.5030\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.2657 - acc: 0.4952 - val_loss: 1.2229 - val_acc: 0.5040\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.2632 - acc: 0.4972 - val_loss: 1.2199 - val_acc: 0.5055\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.2570 - acc: 0.5055 - val_loss: 1.2170 - val_acc: 0.5060\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.2542 - acc: 0.5067 - val_loss: 1.2142 - val_acc: 0.5065\n","va acc: 0.521875\n","te acc: 0.5065\n","Age\n","stack:1/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.8934 - acc: 0.1839 - val_loss: 1.9071 - val_acc: 0.1625\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.8857 - acc: 0.1817 - val_loss: 1.8929 - val_acc: 0.1725\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.8678 - acc: 0.1955 - val_loss: 1.8789 - val_acc: 0.1830\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.8545 - acc: 0.2027 - val_loss: 1.8651 - val_acc: 0.1910\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.8428 - acc: 0.2020 - val_loss: 1.8515 - val_acc: 0.1980\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.8302 - acc: 0.2153 - val_loss: 1.8381 - val_acc: 0.2085\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.8162 - acc: 0.2188 - val_loss: 1.8249 - val_acc: 0.2180\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.8023 - acc: 0.2305 - val_loss: 1.8118 - val_acc: 0.2270\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.7908 - acc: 0.2344 - val_loss: 1.7991 - val_acc: 0.2325\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.7765 - acc: 0.2497 - val_loss: 1.7866 - val_acc: 0.2400\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.7668 - acc: 0.2541 - val_loss: 1.7743 - val_acc: 0.2450\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.7555 - acc: 0.2523 - val_loss: 1.7623 - val_acc: 0.2515\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.7442 - acc: 0.2713 - val_loss: 1.7505 - val_acc: 0.2625\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.7365 - acc: 0.2755 - val_loss: 1.7390 - val_acc: 0.2690\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.7217 - acc: 0.2784 - val_loss: 1.7277 - val_acc: 0.2795\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.7071 - acc: 0.2934 - val_loss: 1.7167 - val_acc: 0.2890\n","va acc: 0.29625\n","te acc: 0.289\n","stack:2/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.7042 - acc: 0.2970 - val_loss: 1.7060 - val_acc: 0.2965\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.6915 - acc: 0.3013 - val_loss: 1.6955 - val_acc: 0.3080\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.6825 - acc: 0.3058 - val_loss: 1.6853 - val_acc: 0.3175\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.6675 - acc: 0.3177 - val_loss: 1.6753 - val_acc: 0.3220\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.6617 - acc: 0.3206 - val_loss: 1.6656 - val_acc: 0.3320\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.6533 - acc: 0.3302 - val_loss: 1.6561 - val_acc: 0.3360\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.6445 - acc: 0.3402 - val_loss: 1.6468 - val_acc: 0.3400\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.6336 - acc: 0.3466 - val_loss: 1.6378 - val_acc: 0.3460\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.6252 - acc: 0.3498 - val_loss: 1.6291 - val_acc: 0.3510\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.6177 - acc: 0.3525 - val_loss: 1.6206 - val_acc: 0.3595\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.6073 - acc: 0.3566 - val_loss: 1.6123 - val_acc: 0.3605\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.6032 - acc: 0.3583 - val_loss: 1.6042 - val_acc: 0.3655\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.5941 - acc: 0.3663 - val_loss: 1.5964 - val_acc: 0.3695\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.5882 - acc: 0.3753 - val_loss: 1.5887 - val_acc: 0.3730\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.5794 - acc: 0.3795 - val_loss: 1.5813 - val_acc: 0.3760\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.5713 - acc: 0.3842 - val_loss: 1.5740 - val_acc: 0.3800\n","va acc: 0.389375\n","te acc: 0.38\n","stack:3/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.5643 - acc: 0.3814 - val_loss: 1.5670 - val_acc: 0.3835\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.5551 - acc: 0.3855 - val_loss: 1.5602 - val_acc: 0.3880\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.5486 - acc: 0.3864 - val_loss: 1.5535 - val_acc: 0.3915\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.5434 - acc: 0.3903 - val_loss: 1.5470 - val_acc: 0.3930\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.5355 - acc: 0.3986 - val_loss: 1.5408 - val_acc: 0.3965\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.5281 - acc: 0.4039 - val_loss: 1.5346 - val_acc: 0.3970\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.5237 - acc: 0.4134 - val_loss: 1.5287 - val_acc: 0.4020\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.5211 - acc: 0.4033 - val_loss: 1.5229 - val_acc: 0.4050\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.5162 - acc: 0.4084 - val_loss: 1.5173 - val_acc: 0.4095\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.5083 - acc: 0.4097 - val_loss: 1.5118 - val_acc: 0.4130\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.4987 - acc: 0.4167 - val_loss: 1.5065 - val_acc: 0.4150\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.5009 - acc: 0.4167 - val_loss: 1.5013 - val_acc: 0.4170\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.4907 - acc: 0.4189 - val_loss: 1.4963 - val_acc: 0.4180\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.4886 - acc: 0.4202 - val_loss: 1.4914 - val_acc: 0.4185\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.4805 - acc: 0.4208 - val_loss: 1.4867 - val_acc: 0.4205\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.4771 - acc: 0.4192 - val_loss: 1.4820 - val_acc: 0.4230\n","va acc: 0.43625\n","te acc: 0.423\n","stack:4/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.4756 - acc: 0.4298 - val_loss: 1.4775 - val_acc: 0.4230\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.4683 - acc: 0.4309 - val_loss: 1.4731 - val_acc: 0.4225\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.4646 - acc: 0.4313 - val_loss: 1.4689 - val_acc: 0.4240\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.4583 - acc: 0.4339 - val_loss: 1.4647 - val_acc: 0.4260\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.4598 - acc: 0.4298 - val_loss: 1.4606 - val_acc: 0.4260\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.4563 - acc: 0.4298 - val_loss: 1.4566 - val_acc: 0.4305\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.4472 - acc: 0.4406 - val_loss: 1.4528 - val_acc: 0.4335\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.4470 - acc: 0.4417 - val_loss: 1.4490 - val_acc: 0.4335\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.4409 - acc: 0.4370 - val_loss: 1.4453 - val_acc: 0.4350\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.4385 - acc: 0.4392 - val_loss: 1.4418 - val_acc: 0.4385\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.4330 - acc: 0.4339 - val_loss: 1.4383 - val_acc: 0.4375\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.4318 - acc: 0.4395 - val_loss: 1.4349 - val_acc: 0.4375\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.4262 - acc: 0.4452 - val_loss: 1.4316 - val_acc: 0.4395\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.4248 - acc: 0.4444 - val_loss: 1.4283 - val_acc: 0.4390\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.4209 - acc: 0.4527 - val_loss: 1.4251 - val_acc: 0.4405\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.4170 - acc: 0.4462 - val_loss: 1.4221 - val_acc: 0.4415\n","va acc: 0.450625\n","te acc: 0.4415\n","stack:5/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 1.4171 - acc: 0.4459 - val_loss: 1.4190 - val_acc: 0.4415\n","Epoch 2/16\n","6400/6400 - 0s - loss: 1.4178 - acc: 0.4441 - val_loss: 1.4161 - val_acc: 0.4425\n","Epoch 3/16\n","6400/6400 - 0s - loss: 1.4119 - acc: 0.4417 - val_loss: 1.4133 - val_acc: 0.4420\n","Epoch 4/16\n","6400/6400 - 0s - loss: 1.4124 - acc: 0.4422 - val_loss: 1.4105 - val_acc: 0.4435\n","Epoch 5/16\n","6400/6400 - 0s - loss: 1.4101 - acc: 0.4466 - val_loss: 1.4077 - val_acc: 0.4430\n","Epoch 6/16\n","6400/6400 - 0s - loss: 1.4054 - acc: 0.4477 - val_loss: 1.4051 - val_acc: 0.4430\n","Epoch 7/16\n","6400/6400 - 0s - loss: 1.4015 - acc: 0.4470 - val_loss: 1.4025 - val_acc: 0.4425\n","Epoch 8/16\n","6400/6400 - 0s - loss: 1.4033 - acc: 0.4459 - val_loss: 1.3999 - val_acc: 0.4415\n","Epoch 9/16\n","6400/6400 - 0s - loss: 1.3993 - acc: 0.4467 - val_loss: 1.3974 - val_acc: 0.4415\n","Epoch 10/16\n","6400/6400 - 0s - loss: 1.3946 - acc: 0.4541 - val_loss: 1.3949 - val_acc: 0.4430\n","Epoch 11/16\n","6400/6400 - 0s - loss: 1.3937 - acc: 0.4502 - val_loss: 1.3925 - val_acc: 0.4440\n","Epoch 12/16\n","6400/6400 - 0s - loss: 1.3914 - acc: 0.4531 - val_loss: 1.3902 - val_acc: 0.4440\n","Epoch 13/16\n","6400/6400 - 0s - loss: 1.3886 - acc: 0.4500 - val_loss: 1.3879 - val_acc: 0.4450\n","Epoch 14/16\n","6400/6400 - 0s - loss: 1.3857 - acc: 0.4578 - val_loss: 1.3857 - val_acc: 0.4445\n","Epoch 15/16\n","6400/6400 - 0s - loss: 1.3837 - acc: 0.4564 - val_loss: 1.3834 - val_acc: 0.4460\n","Epoch 16/16\n","6400/6400 - 0s - loss: 1.3828 - acc: 0.4514 - val_loss: 1.3813 - val_acc: 0.4465\n","va acc: 0.47875\n","te acc: 0.4465\n","Gender\n","stack:1/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.7484 - acc: 0.5164 - val_loss: 0.7336 - val_acc: 0.5235\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.7418 - acc: 0.5231 - val_loss: 0.7270 - val_acc: 0.5310\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.7360 - acc: 0.5298 - val_loss: 0.7206 - val_acc: 0.5360\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.7317 - acc: 0.5272 - val_loss: 0.7144 - val_acc: 0.5435\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.7235 - acc: 0.5409 - val_loss: 0.7083 - val_acc: 0.5535\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.7159 - acc: 0.5445 - val_loss: 0.7025 - val_acc: 0.5555\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.7135 - acc: 0.5511 - val_loss: 0.6968 - val_acc: 0.5625\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.7093 - acc: 0.5523 - val_loss: 0.6913 - val_acc: 0.5710\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.7012 - acc: 0.5589 - val_loss: 0.6859 - val_acc: 0.5775\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.6951 - acc: 0.5727 - val_loss: 0.6807 - val_acc: 0.5800\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.6887 - acc: 0.5820 - val_loss: 0.6757 - val_acc: 0.5880\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.6835 - acc: 0.5850 - val_loss: 0.6708 - val_acc: 0.5950\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.6807 - acc: 0.5923 - val_loss: 0.6661 - val_acc: 0.6015\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.6756 - acc: 0.5902 - val_loss: 0.6615 - val_acc: 0.6095\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.6687 - acc: 0.5998 - val_loss: 0.6570 - val_acc: 0.6180\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.6656 - acc: 0.6062 - val_loss: 0.6527 - val_acc: 0.6195\n","va acc: 0.613125\n","te acc: 0.6195\n","stack:2/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.6633 - acc: 0.6036 - val_loss: 0.6485 - val_acc: 0.6215\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.6614 - acc: 0.6062 - val_loss: 0.6443 - val_acc: 0.6280\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.6569 - acc: 0.6159 - val_loss: 0.6404 - val_acc: 0.6325\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.6515 - acc: 0.6239 - val_loss: 0.6366 - val_acc: 0.6390\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.6505 - acc: 0.6233 - val_loss: 0.6329 - val_acc: 0.6420\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.6430 - acc: 0.6347 - val_loss: 0.6293 - val_acc: 0.6450\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.6402 - acc: 0.6389 - val_loss: 0.6258 - val_acc: 0.6450\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.6381 - acc: 0.6369 - val_loss: 0.6224 - val_acc: 0.6480\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.6319 - acc: 0.6480 - val_loss: 0.6191 - val_acc: 0.6520\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.6330 - acc: 0.6473 - val_loss: 0.6160 - val_acc: 0.6570\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.6270 - acc: 0.6514 - val_loss: 0.6129 - val_acc: 0.6605\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.6222 - acc: 0.6553 - val_loss: 0.6099 - val_acc: 0.6630\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.6182 - acc: 0.6619 - val_loss: 0.6071 - val_acc: 0.6670\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.6177 - acc: 0.6606 - val_loss: 0.6043 - val_acc: 0.6720\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.6137 - acc: 0.6694 - val_loss: 0.6016 - val_acc: 0.6765\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.6098 - acc: 0.6684 - val_loss: 0.5990 - val_acc: 0.6785\n","va acc: 0.693125\n","te acc: 0.6785\n","stack:3/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.5984 - acc: 0.6786 - val_loss: 0.5964 - val_acc: 0.6800\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.5953 - acc: 0.6831 - val_loss: 0.5939 - val_acc: 0.6805\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.5949 - acc: 0.6820 - val_loss: 0.5915 - val_acc: 0.6820\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.5896 - acc: 0.6873 - val_loss: 0.5892 - val_acc: 0.6820\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.5915 - acc: 0.6850 - val_loss: 0.5869 - val_acc: 0.6840\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.5866 - acc: 0.6936 - val_loss: 0.5847 - val_acc: 0.6855\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.5854 - acc: 0.6903 - val_loss: 0.5826 - val_acc: 0.6885\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.5827 - acc: 0.6959 - val_loss: 0.5805 - val_acc: 0.6905\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.5800 - acc: 0.6980 - val_loss: 0.5785 - val_acc: 0.6915\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.5766 - acc: 0.7055 - val_loss: 0.5766 - val_acc: 0.6930\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.5746 - acc: 0.7058 - val_loss: 0.5747 - val_acc: 0.6955\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.5738 - acc: 0.7100 - val_loss: 0.5729 - val_acc: 0.6995\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.5730 - acc: 0.7069 - val_loss: 0.5711 - val_acc: 0.7030\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.5681 - acc: 0.7142 - val_loss: 0.5694 - val_acc: 0.7050\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.5672 - acc: 0.7148 - val_loss: 0.5678 - val_acc: 0.7060\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.5632 - acc: 0.7195 - val_loss: 0.5662 - val_acc: 0.7055\n","va acc: 0.69375\n","te acc: 0.7055\n","stack:4/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.5716 - acc: 0.7088 - val_loss: 0.5647 - val_acc: 0.7055\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.5684 - acc: 0.7134 - val_loss: 0.5632 - val_acc: 0.7075\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.5669 - acc: 0.7173 - val_loss: 0.5618 - val_acc: 0.7085\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.5655 - acc: 0.7180 - val_loss: 0.5604 - val_acc: 0.7100\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.5660 - acc: 0.7120 - val_loss: 0.5591 - val_acc: 0.7115\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.5633 - acc: 0.7136 - val_loss: 0.5578 - val_acc: 0.7125\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.5620 - acc: 0.7177 - val_loss: 0.5565 - val_acc: 0.7135\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.5602 - acc: 0.7219 - val_loss: 0.5553 - val_acc: 0.7150\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.5625 - acc: 0.7161 - val_loss: 0.5541 - val_acc: 0.7165\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.5583 - acc: 0.7242 - val_loss: 0.5529 - val_acc: 0.7185\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.5564 - acc: 0.7256 - val_loss: 0.5518 - val_acc: 0.7180\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.5557 - acc: 0.7234 - val_loss: 0.5507 - val_acc: 0.7185\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.5562 - acc: 0.7216 - val_loss: 0.5496 - val_acc: 0.7195\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.5543 - acc: 0.7277 - val_loss: 0.5486 - val_acc: 0.7200\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.5526 - acc: 0.7269 - val_loss: 0.5476 - val_acc: 0.7210\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.5502 - acc: 0.7222 - val_loss: 0.5466 - val_acc: 0.7210\n","va acc: 0.75125\n","te acc: 0.721\n","stack:5/5\n","Train on 6400 samples, validate on 2000 samples\n","Epoch 1/16\n","6400/6400 - 0s - loss: 0.5482 - acc: 0.7322 - val_loss: 0.5456 - val_acc: 0.7215\n","Epoch 2/16\n","6400/6400 - 0s - loss: 0.5435 - acc: 0.7384 - val_loss: 0.5446 - val_acc: 0.7225\n","Epoch 3/16\n","6400/6400 - 0s - loss: 0.5457 - acc: 0.7325 - val_loss: 0.5437 - val_acc: 0.7240\n","Epoch 4/16\n","6400/6400 - 0s - loss: 0.5431 - acc: 0.7355 - val_loss: 0.5428 - val_acc: 0.7245\n","Epoch 5/16\n","6400/6400 - 0s - loss: 0.5434 - acc: 0.7350 - val_loss: 0.5419 - val_acc: 0.7260\n","Epoch 6/16\n","6400/6400 - 0s - loss: 0.5417 - acc: 0.7423 - val_loss: 0.5410 - val_acc: 0.7290\n","Epoch 7/16\n","6400/6400 - 0s - loss: 0.5396 - acc: 0.7369 - val_loss: 0.5402 - val_acc: 0.7305\n","Epoch 8/16\n","6400/6400 - 0s - loss: 0.5400 - acc: 0.7408 - val_loss: 0.5393 - val_acc: 0.7310\n","Epoch 9/16\n","6400/6400 - 0s - loss: 0.5398 - acc: 0.7366 - val_loss: 0.5385 - val_acc: 0.7325\n","Epoch 10/16\n","6400/6400 - 0s - loss: 0.5361 - acc: 0.7406 - val_loss: 0.5377 - val_acc: 0.7325\n","Epoch 11/16\n","6400/6400 - 0s - loss: 0.5355 - acc: 0.7427 - val_loss: 0.5370 - val_acc: 0.7345\n","Epoch 12/16\n","6400/6400 - 0s - loss: 0.5357 - acc: 0.7428 - val_loss: 0.5362 - val_acc: 0.7370\n","Epoch 13/16\n","6400/6400 - 0s - loss: 0.5291 - acc: 0.7477 - val_loss: 0.5355 - val_acc: 0.7375\n","Epoch 14/16\n","6400/6400 - 0s - loss: 0.5326 - acc: 0.7442 - val_loss: 0.5348 - val_acc: 0.7375\n","Epoch 15/16\n","6400/6400 - 0s - loss: 0.5346 - acc: 0.7419 - val_loss: 0.5341 - val_acc: 0.7370\n","Epoch 16/16\n","6400/6400 - 0s - loss: 0.5299 - acc: 0.7431 - val_loss: 0.5334 - val_acc: 0.7375\n","va acc: 0.748125\n","te acc: 0.7375\n","done!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pfr3HnpcWGOI","colab_type":"code","outputId":"7c8c3bd8-955c-4b69-c3c0-a13a1a877483","executionInfo":{"status":"ok","timestamp":1571328803099,"user_tz":-480,"elapsed":26726,"user":{"displayName":"Huolin PENG","photoUrl":"","userId":"03589708627092955464"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","\n","\n","def xgb_acc_score(preds, dtrain):\n","    y_true = dtrain.get_label()\n","    y_pred = np.argmax(preds, axis=1)\n","    return [('acc', np.mean(y_true == y_pred))]\n","\n","\n","df_lr = pd.read_csv('./data/tfidf_stack_1w.csv')\n","df_dm = pd.read_csv('./data/dm_stack_1w.csv')\n","df_dbow = pd.read_csv('./data/dbow_stack_1w.csv')\n","\n","df_lb = pd.read_csv('./data/all_v2.csv', usecols=['ID', 'Education', 'Age', 'Gender'], nrows=10000)\n","ys = {}\n","for lb in ['Education', 'Age', 'Gender']:\n","    ys[lb] = np.array(df_lb[lb])\n","\n","df = pd.concat([df_lr, df_dm, df_dbow], axis=1)\n","print(df.columns)\n","\n","TR = 8000\n","df_sub = pd.DataFrame()\n","df_sub['ID'] = df_lb.iloc[TR:]['ID']\n","seed = 10\n","\n","# -------------------------education----------------------------------\n","lb = 'Education'\n","print(lb)\n","\n","esr = 25\n","evals = 1\n","n_trees = 1000\n","\n","num_class = len(pd.value_counts(ys[lb]))\n","X = df.iloc[:TR]\n","y = ys[lb][:TR]\n","X_te = df.iloc[TR:]\n","y_te = ys[lb][TR:]\n","\n","ss = 0.9\n","mc = 2\n","md = 8\n","gm = 2\n","\n","params = {\n","    'objective': 'multi:softprob',\n","    'booster': 'gbtree',\n","    'num_class': num_class,\n","    'max_depth': md,\n","    'min_child_weight': mc,\n","    'subsample': ss,\n","    'colsample_bytree': 0.8,\n","    'gamma': gm,\n","    'eta': 0.01,\n","    'lambda': 0,\n","    'alpha': 0,\n","    'silent': 1\n","}\n","\n","dtrain = xgb.DMatrix(X, y)\n","dvalid = xgb.DMatrix(X_te, y_te)\n","watchlist = [(dtrain, 'dtrain'), (dvalid, 'eval')]\n","bst = xgb.train(params, dtrain, n_trees, evals=watchlist, feval=xgb_acc_score, maximize=True,\n","                early_stopping_rounds=esr, verbose_eval=evals)\n","df_sub['Education'] = np.argmax(bst.predict(dvalid), axis=1) + 1\n","\n","# ------------------------ age-----------------------------------\n","lb = 'Age'\n","print(lb)\n","num_class = len(pd.value_counts(ys[lb]))\n","\n","num_class = len(pd.value_counts(ys[lb]))\n","X = df.iloc[:TR]\n","y = ys[lb][:TR]\n","X_te = df.iloc[TR:]\n","y_te = ys[lb][TR:]\n","\n","ss = 0.5\n","mc = 3\n","md = 7\n","gm = 2\n","\n","params = {\n","    \"objective\": \"multi:softprob\",\n","    \"booster\": \"gbtree\",\n","    \"num_class\": num_class,\n","    'max_depth': md,\n","    'min_child_weight': mc,\n","    'subsample': ss,\n","    'colsample_bytree': 1,\n","    'gamma': gm,\n","    \"eta\": 0.01,\n","    \"lambda\": 0,\n","    'alpha': 0,\n","    \"silent\": 1,\n","}\n","\n","dtrain = xgb.DMatrix(X, y)\n","dvalid = xgb.DMatrix(X_te, y_te)\n","watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n","bst = xgb.train(params, dtrain, n_trees, evals=watchlist, feval=xgb_acc_score, maximize=True,\n","                early_stopping_rounds=esr, verbose_eval=evals)\n","df_sub['Age'] = np.argmax(bst.predict(dvalid), axis=1)+1\n","\n","# --------------------------gender-------------------------------------\n","lb = 'Gender'\n","print(lb)\n","num_class = len(pd.value_counts(ys[lb]))\n","\n","num_class = len(pd.value_counts(ys[lb]))\n","X = df.iloc[:TR]\n","y = ys[lb][:TR]\n","X_te = df.iloc[TR:]\n","y_te = ys[lb][TR:]\n","\n","ss = 0.5\n","mc = 0.8\n","md = 7\n","gm = 1\n","\n","params = {\n","    \"objective\": \"multi:softprob\",\n","    \"booster\": \"gbtree\",\n","    \"num_class\": num_class,\n","    'max_depth': md,\n","    'min_child_weight': mc,\n","    'subsample': ss,\n","    'colsample_bytree': 1,\n","    'gamma': gm,\n","    \"eta\": 0.01,\n","    \"lambda\": 0,\n","    'alpha': 0,\n","    \"silent\": 1,\n","}\n","\n","dtrain = xgb.DMatrix(X, y)\n","dvalid = xgb.DMatrix(X_te, y_te)\n","watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n","bst = xgb.train(params, dtrain, n_trees, evals=watchlist, feval=xgb_acc_score, maximize=True,\n","                early_stopping_rounds=esr, verbose_eval=evals)\n","df_sub['Gender'] = np.argmax(bst.predict(dvalid), axis=1) + 1\n","\n","# df_sub = df_sub[['ID','Age','Gender','Education']]  # 不知道为什么要加这一句，这样就将三个属性直接打乱了\n","df_sub.to_csv('./data/tfidf_dm_dbow_2k.csv', index=None)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Index(['tfidf_Education_0', 'tfidf_Education_1', 'tfidf_Education_2',\n","       'tfidf_Education_3', 'tfidf_Education_4', 'tfidf_Education_5',\n","       'tfidf_Age_0', 'tfidf_Age_1', 'tfidf_Age_2', 'tfidf_Age_3',\n","       'tfidf_Age_4', 'tfidf_Age_5', 'tfidf_Gender_0', 'tfidf_Gender_1',\n","       'dm_nn_Education_0', 'dm_nn_Education_1', 'dm_nn_Education_2',\n","       'dm_nn_Education_3', 'dm_nn_Education_4', 'dm_nn_Education_5',\n","       'dm_nn_Age_0', 'dm_nn_Age_1', 'dm_nn_Age_2', 'dm_nn_Age_3',\n","       'dm_nn_Age_4', 'dm_nn_Age_5', 'dm_nn_Gender_0', 'dm_nn_Gender_1',\n","       'dbow_nn_Education_0', 'dbow_nn_Education_1', 'dbow_nn_Education_2',\n","       'dbow_nn_Education_3', 'dbow_nn_Education_4', 'dbow_nn_Education_5',\n","       'dbow_nn_Age_0', 'dbow_nn_Age_1', 'dbow_nn_Age_2', 'dbow_nn_Age_3',\n","       'dbow_nn_Age_4', 'dbow_nn_Age_5', 'dbow_nn_Gender_0',\n","       'dbow_nn_Gender_1'],\n","      dtype='object')\n","Education\n","[0]\tdtrain-merror:0.294\teval-merror:0.3905\tdtrain-acc:0.706\teval-acc:0.6095\n","Multiple eval metrics have been passed: 'eval-acc' will be used for early stopping.\n","\n","Will train until eval-acc hasn't improved in 25 rounds.\n","[1]\tdtrain-merror:0.272125\teval-merror:0.375\tdtrain-acc:0.727875\teval-acc:0.625\n","[2]\tdtrain-merror:0.26875\teval-merror:0.3715\tdtrain-acc:0.73125\teval-acc:0.6285\n","[3]\tdtrain-merror:0.263375\teval-merror:0.3745\tdtrain-acc:0.736625\teval-acc:0.6255\n","[4]\tdtrain-merror:0.262125\teval-merror:0.366\tdtrain-acc:0.737875\teval-acc:0.634\n","[5]\tdtrain-merror:0.259125\teval-merror:0.362\tdtrain-acc:0.740875\teval-acc:0.638\n","[6]\tdtrain-merror:0.256375\teval-merror:0.3625\tdtrain-acc:0.743625\teval-acc:0.6375\n","[7]\tdtrain-merror:0.251625\teval-merror:0.365\tdtrain-acc:0.748375\teval-acc:0.635\n","[8]\tdtrain-merror:0.252375\teval-merror:0.364\tdtrain-acc:0.747625\teval-acc:0.636\n","[9]\tdtrain-merror:0.25075\teval-merror:0.3675\tdtrain-acc:0.74925\teval-acc:0.6325\n","[10]\tdtrain-merror:0.24975\teval-merror:0.363\tdtrain-acc:0.75025\teval-acc:0.637\n","[11]\tdtrain-merror:0.2485\teval-merror:0.364\tdtrain-acc:0.7515\teval-acc:0.636\n","[12]\tdtrain-merror:0.246125\teval-merror:0.364\tdtrain-acc:0.753875\teval-acc:0.636\n","[13]\tdtrain-merror:0.245625\teval-merror:0.3665\tdtrain-acc:0.754375\teval-acc:0.6335\n","[14]\tdtrain-merror:0.2455\teval-merror:0.363\tdtrain-acc:0.7545\teval-acc:0.637\n","[15]\tdtrain-merror:0.243625\teval-merror:0.366\tdtrain-acc:0.756375\teval-acc:0.634\n","[16]\tdtrain-merror:0.243625\teval-merror:0.365\tdtrain-acc:0.756375\teval-acc:0.635\n","[17]\tdtrain-merror:0.24275\teval-merror:0.3625\tdtrain-acc:0.75725\teval-acc:0.6375\n","[18]\tdtrain-merror:0.242125\teval-merror:0.36\tdtrain-acc:0.757875\teval-acc:0.64\n","[19]\tdtrain-merror:0.23875\teval-merror:0.36\tdtrain-acc:0.76125\teval-acc:0.64\n","[20]\tdtrain-merror:0.238\teval-merror:0.358\tdtrain-acc:0.762\teval-acc:0.642\n","[21]\tdtrain-merror:0.236\teval-merror:0.3575\tdtrain-acc:0.764\teval-acc:0.6425\n","[22]\tdtrain-merror:0.236125\teval-merror:0.357\tdtrain-acc:0.763875\teval-acc:0.643\n","[23]\tdtrain-merror:0.23725\teval-merror:0.358\tdtrain-acc:0.76275\teval-acc:0.642\n","[24]\tdtrain-merror:0.2345\teval-merror:0.359\tdtrain-acc:0.7655\teval-acc:0.641\n","[25]\tdtrain-merror:0.23425\teval-merror:0.358\tdtrain-acc:0.76575\teval-acc:0.642\n","[26]\tdtrain-merror:0.234625\teval-merror:0.3585\tdtrain-acc:0.765375\teval-acc:0.6415\n","[27]\tdtrain-merror:0.233625\teval-merror:0.3605\tdtrain-acc:0.766375\teval-acc:0.6395\n","[28]\tdtrain-merror:0.23275\teval-merror:0.359\tdtrain-acc:0.76725\teval-acc:0.641\n","[29]\tdtrain-merror:0.23025\teval-merror:0.36\tdtrain-acc:0.76975\teval-acc:0.64\n","[30]\tdtrain-merror:0.22925\teval-merror:0.3575\tdtrain-acc:0.77075\teval-acc:0.6425\n","[31]\tdtrain-merror:0.228875\teval-merror:0.3575\tdtrain-acc:0.771125\teval-acc:0.6425\n","[32]\tdtrain-merror:0.228875\teval-merror:0.3575\tdtrain-acc:0.771125\teval-acc:0.6425\n","[33]\tdtrain-merror:0.228\teval-merror:0.3595\tdtrain-acc:0.772\teval-acc:0.6405\n","[34]\tdtrain-merror:0.227875\teval-merror:0.3605\tdtrain-acc:0.772125\teval-acc:0.6395\n","[35]\tdtrain-merror:0.226625\teval-merror:0.358\tdtrain-acc:0.773375\teval-acc:0.642\n","[36]\tdtrain-merror:0.225625\teval-merror:0.3585\tdtrain-acc:0.774375\teval-acc:0.6415\n","[37]\tdtrain-merror:0.2265\teval-merror:0.3605\tdtrain-acc:0.7735\teval-acc:0.6395\n","[38]\tdtrain-merror:0.224875\teval-merror:0.3585\tdtrain-acc:0.775125\teval-acc:0.6415\n","[39]\tdtrain-merror:0.222875\teval-merror:0.3575\tdtrain-acc:0.777125\teval-acc:0.6425\n","[40]\tdtrain-merror:0.2235\teval-merror:0.361\tdtrain-acc:0.7765\teval-acc:0.639\n","[41]\tdtrain-merror:0.221625\teval-merror:0.3605\tdtrain-acc:0.778375\teval-acc:0.6395\n","[42]\tdtrain-merror:0.22325\teval-merror:0.3615\tdtrain-acc:0.77675\teval-acc:0.6385\n","[43]\tdtrain-merror:0.223125\teval-merror:0.3625\tdtrain-acc:0.776875\teval-acc:0.6375\n","[44]\tdtrain-merror:0.224\teval-merror:0.3615\tdtrain-acc:0.776\teval-acc:0.6385\n","[45]\tdtrain-merror:0.22375\teval-merror:0.3605\tdtrain-acc:0.77625\teval-acc:0.6395\n","[46]\tdtrain-merror:0.22325\teval-merror:0.3605\tdtrain-acc:0.77675\teval-acc:0.6395\n","[47]\tdtrain-merror:0.222\teval-merror:0.3605\tdtrain-acc:0.778\teval-acc:0.6395\n","Stopping. Best iteration:\n","[22]\tdtrain-merror:0.236125\teval-merror:0.357\tdtrain-acc:0.763875\teval-acc:0.643\n","\n","Age\n","[0]\ttrain-merror:0.382625\teval-merror:0.4515\ttrain-acc:0.617375\teval-acc:0.5485\n","Multiple eval metrics have been passed: 'eval-acc' will be used for early stopping.\n","\n","Will train until eval-acc hasn't improved in 25 rounds.\n","[1]\ttrain-merror:0.35025\teval-merror:0.4385\ttrain-acc:0.64975\teval-acc:0.5615\n","[2]\ttrain-merror:0.345625\teval-merror:0.4345\ttrain-acc:0.654375\teval-acc:0.5655\n","[3]\ttrain-merror:0.34\teval-merror:0.4305\ttrain-acc:0.66\teval-acc:0.5695\n","[4]\ttrain-merror:0.336375\teval-merror:0.4295\ttrain-acc:0.663625\teval-acc:0.5705\n","[5]\ttrain-merror:0.336625\teval-merror:0.427\ttrain-acc:0.663375\teval-acc:0.573\n","[6]\ttrain-merror:0.3355\teval-merror:0.4265\ttrain-acc:0.6645\teval-acc:0.5735\n","[7]\ttrain-merror:0.33225\teval-merror:0.422\ttrain-acc:0.66775\teval-acc:0.578\n","[8]\ttrain-merror:0.3325\teval-merror:0.416\ttrain-acc:0.6675\teval-acc:0.584\n","[9]\ttrain-merror:0.33075\teval-merror:0.416\ttrain-acc:0.66925\teval-acc:0.584\n","[10]\ttrain-merror:0.328875\teval-merror:0.4175\ttrain-acc:0.671125\teval-acc:0.5825\n","[11]\ttrain-merror:0.326125\teval-merror:0.415\ttrain-acc:0.673875\teval-acc:0.585\n","[12]\ttrain-merror:0.32675\teval-merror:0.412\ttrain-acc:0.67325\teval-acc:0.588\n","[13]\ttrain-merror:0.328125\teval-merror:0.4105\ttrain-acc:0.671875\teval-acc:0.5895\n","[14]\ttrain-merror:0.327875\teval-merror:0.4125\ttrain-acc:0.672125\teval-acc:0.5875\n","[15]\ttrain-merror:0.32725\teval-merror:0.4165\ttrain-acc:0.67275\teval-acc:0.5835\n","[16]\ttrain-merror:0.324625\teval-merror:0.4165\ttrain-acc:0.675375\teval-acc:0.5835\n","[17]\ttrain-merror:0.325375\teval-merror:0.415\ttrain-acc:0.674625\teval-acc:0.585\n","[18]\ttrain-merror:0.326125\teval-merror:0.416\ttrain-acc:0.673875\teval-acc:0.584\n","[19]\ttrain-merror:0.3255\teval-merror:0.4175\ttrain-acc:0.6745\teval-acc:0.5825\n","[20]\ttrain-merror:0.3245\teval-merror:0.4195\ttrain-acc:0.6755\teval-acc:0.5805\n","[21]\ttrain-merror:0.325625\teval-merror:0.417\ttrain-acc:0.674375\teval-acc:0.583\n","[22]\ttrain-merror:0.324625\teval-merror:0.4165\ttrain-acc:0.675375\teval-acc:0.5835\n","[23]\ttrain-merror:0.321625\teval-merror:0.418\ttrain-acc:0.678375\teval-acc:0.582\n","[24]\ttrain-merror:0.323375\teval-merror:0.416\ttrain-acc:0.676625\teval-acc:0.584\n","[25]\ttrain-merror:0.32225\teval-merror:0.4175\ttrain-acc:0.67775\teval-acc:0.5825\n","[26]\ttrain-merror:0.322625\teval-merror:0.415\ttrain-acc:0.677375\teval-acc:0.585\n","[27]\ttrain-merror:0.322125\teval-merror:0.417\ttrain-acc:0.677875\teval-acc:0.583\n","[28]\ttrain-merror:0.3215\teval-merror:0.415\ttrain-acc:0.6785\teval-acc:0.585\n","[29]\ttrain-merror:0.32275\teval-merror:0.416\ttrain-acc:0.67725\teval-acc:0.584\n","[30]\ttrain-merror:0.321125\teval-merror:0.4125\ttrain-acc:0.678875\teval-acc:0.5875\n","[31]\ttrain-merror:0.32275\teval-merror:0.412\ttrain-acc:0.67725\teval-acc:0.588\n","[32]\ttrain-merror:0.323\teval-merror:0.4155\ttrain-acc:0.677\teval-acc:0.5845\n","[33]\ttrain-merror:0.32225\teval-merror:0.4135\ttrain-acc:0.67775\teval-acc:0.5865\n","[34]\ttrain-merror:0.321625\teval-merror:0.414\ttrain-acc:0.678375\teval-acc:0.586\n","[35]\ttrain-merror:0.32125\teval-merror:0.4155\ttrain-acc:0.67875\teval-acc:0.5845\n","[36]\ttrain-merror:0.32025\teval-merror:0.4145\ttrain-acc:0.67975\teval-acc:0.5855\n","[37]\ttrain-merror:0.3195\teval-merror:0.415\ttrain-acc:0.6805\teval-acc:0.585\n","[38]\ttrain-merror:0.317\teval-merror:0.415\ttrain-acc:0.683\teval-acc:0.585\n","Stopping. Best iteration:\n","[13]\ttrain-merror:0.328125\teval-merror:0.4105\ttrain-acc:0.671875\teval-acc:0.5895\n","\n","Gender\n","[0]\ttrain-merror:0.16125\teval-merror:0.197\ttrain-acc:0.83875\teval-acc:0.803\n","Multiple eval metrics have been passed: 'eval-acc' will be used for early stopping.\n","\n","Will train until eval-acc hasn't improved in 25 rounds.\n","[1]\ttrain-merror:0.154125\teval-merror:0.188\ttrain-acc:0.845875\teval-acc:0.812\n","[2]\ttrain-merror:0.15325\teval-merror:0.1915\ttrain-acc:0.84675\teval-acc:0.8085\n","[3]\ttrain-merror:0.153875\teval-merror:0.1905\ttrain-acc:0.846125\teval-acc:0.8095\n","[4]\ttrain-merror:0.151125\teval-merror:0.1895\ttrain-acc:0.848875\teval-acc:0.8105\n","[5]\ttrain-merror:0.149625\teval-merror:0.189\ttrain-acc:0.850375\teval-acc:0.811\n","[6]\ttrain-merror:0.150625\teval-merror:0.189\ttrain-acc:0.849375\teval-acc:0.811\n","[7]\ttrain-merror:0.147875\teval-merror:0.189\ttrain-acc:0.852125\teval-acc:0.811\n","[8]\ttrain-merror:0.1485\teval-merror:0.1885\ttrain-acc:0.8515\teval-acc:0.8115\n","[9]\ttrain-merror:0.148\teval-merror:0.187\ttrain-acc:0.852\teval-acc:0.813\n","[10]\ttrain-merror:0.148625\teval-merror:0.184\ttrain-acc:0.851375\teval-acc:0.816\n","[11]\ttrain-merror:0.149875\teval-merror:0.183\ttrain-acc:0.850125\teval-acc:0.817\n","[12]\ttrain-merror:0.14975\teval-merror:0.183\ttrain-acc:0.85025\teval-acc:0.817\n","[13]\ttrain-merror:0.14925\teval-merror:0.1835\ttrain-acc:0.85075\teval-acc:0.8165\n","[14]\ttrain-merror:0.14775\teval-merror:0.1815\ttrain-acc:0.85225\teval-acc:0.8185\n","[15]\ttrain-merror:0.14725\teval-merror:0.1825\ttrain-acc:0.85275\teval-acc:0.8175\n","[16]\ttrain-merror:0.146875\teval-merror:0.1825\ttrain-acc:0.853125\teval-acc:0.8175\n","[17]\ttrain-merror:0.146\teval-merror:0.1825\ttrain-acc:0.854\teval-acc:0.8175\n","[18]\ttrain-merror:0.147375\teval-merror:0.1815\ttrain-acc:0.852625\teval-acc:0.8185\n","[19]\ttrain-merror:0.14675\teval-merror:0.1805\ttrain-acc:0.85325\teval-acc:0.8195\n","[20]\ttrain-merror:0.146625\teval-merror:0.179\ttrain-acc:0.853375\teval-acc:0.821\n","[21]\ttrain-merror:0.145875\teval-merror:0.18\ttrain-acc:0.854125\teval-acc:0.82\n","[22]\ttrain-merror:0.146875\teval-merror:0.18\ttrain-acc:0.853125\teval-acc:0.82\n","[23]\ttrain-merror:0.146625\teval-merror:0.179\ttrain-acc:0.853375\teval-acc:0.821\n","[24]\ttrain-merror:0.14675\teval-merror:0.18\ttrain-acc:0.85325\teval-acc:0.82\n","[25]\ttrain-merror:0.14625\teval-merror:0.181\ttrain-acc:0.85375\teval-acc:0.819\n","[26]\ttrain-merror:0.146375\teval-merror:0.1805\ttrain-acc:0.853625\teval-acc:0.8195\n","[27]\ttrain-merror:0.14625\teval-merror:0.18\ttrain-acc:0.85375\teval-acc:0.82\n","[28]\ttrain-merror:0.146375\teval-merror:0.1805\ttrain-acc:0.853625\teval-acc:0.8195\n","[29]\ttrain-merror:0.146125\teval-merror:0.181\ttrain-acc:0.853875\teval-acc:0.819\n","[30]\ttrain-merror:0.1455\teval-merror:0.1805\ttrain-acc:0.8545\teval-acc:0.8195\n","[31]\ttrain-merror:0.146\teval-merror:0.1805\ttrain-acc:0.854\teval-acc:0.8195\n","[32]\ttrain-merror:0.146125\teval-merror:0.181\ttrain-acc:0.853875\teval-acc:0.819\n","[33]\ttrain-merror:0.145125\teval-merror:0.181\ttrain-acc:0.854875\teval-acc:0.819\n","[34]\ttrain-merror:0.145625\teval-merror:0.181\ttrain-acc:0.854375\teval-acc:0.819\n","[35]\ttrain-merror:0.145625\teval-merror:0.181\ttrain-acc:0.854375\teval-acc:0.819\n","[36]\ttrain-merror:0.145\teval-merror:0.1805\ttrain-acc:0.855\teval-acc:0.8195\n","[37]\ttrain-merror:0.144875\teval-merror:0.181\ttrain-acc:0.855125\teval-acc:0.819\n","[38]\ttrain-merror:0.144625\teval-merror:0.18\ttrain-acc:0.855375\teval-acc:0.82\n","[39]\ttrain-merror:0.144875\teval-merror:0.181\ttrain-acc:0.855125\teval-acc:0.819\n","[40]\ttrain-merror:0.14475\teval-merror:0.1805\ttrain-acc:0.85525\teval-acc:0.8195\n","[41]\ttrain-merror:0.144375\teval-merror:0.181\ttrain-acc:0.855625\teval-acc:0.819\n","[42]\ttrain-merror:0.1445\teval-merror:0.181\ttrain-acc:0.8555\teval-acc:0.819\n","[43]\ttrain-merror:0.144125\teval-merror:0.18\ttrain-acc:0.855875\teval-acc:0.82\n","[44]\ttrain-merror:0.144125\teval-merror:0.1815\ttrain-acc:0.855875\teval-acc:0.8185\n","[45]\ttrain-merror:0.143625\teval-merror:0.181\ttrain-acc:0.856375\teval-acc:0.819\n","Stopping. Best iteration:\n","[20]\ttrain-merror:0.146625\teval-merror:0.179\ttrain-acc:0.853375\teval-acc:0.821\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HQ3Arul3TpmH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}